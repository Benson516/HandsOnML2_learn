{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9cc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a804c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "#\n",
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab07ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d20ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a28d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_full, y_train_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb78c1f",
   "metadata": {},
   "source": [
    "# The Vanishing/Exploding Gradients Problems\n",
    "## glorot and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0192a767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7ff3a4a24198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He initialization (for ReLU), normal distribution\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579d6d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7ff3a4a45eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He initialization (for ReLU), uniform distribution\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                                distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc76c50",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd74bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky ReLU\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    # ReLU, not specifying the initialization method\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    # Leaky ReLU, with He-normal initializer\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    # SELU (must use the LeCun normal initializer, sigma^2 = 1/fan_in )\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    #\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5595176",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2370a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f0c14f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06c45f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb67516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benson516/ml/my_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1331: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8a77e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the batch normalization before activation\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93d9f1",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df7c901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab7d40",
   "metadata": {},
   "source": [
    "# Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63329a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d871a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d01c5b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43986, 28, 28)\n",
      "(200, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_A.shape)\n",
    "print(X_train_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3b62ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 5 7 7 7 4 4 3 4 0 1 6 3 4 3 2 6 5 3 4 5 1 3 4 2 0 6 7 1]\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_A[:30])\n",
    "print(y_train_B[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c33664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "395fe2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cb5bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the model_A\n",
    "# model_A = keras.models.Sequential()\n",
    "# model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# for n_hidden in (300, 100, 50, 50, 50):\n",
    "#     model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "# model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640ee25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#                 optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "#                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73d5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "#                     validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df01334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d80fad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive solution: use the same model architecture as model_A\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64b40a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benson516/ml/my_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e573cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "#                       validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f8e01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45e978",
   "metadata": {},
   "source": [
    "## Transfer Learning with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88cd6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the model_A to generate model_B for the second task\n",
    "# **Note: The layers' weights are shared. \n",
    "#         Training one will affect another!!\n",
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) # Use \"layers\" member to access layers\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0df009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the model_A before constructing another network\n",
    "model_A_clone = keras.models.clone_model(model_A) # Clone the \"architecture\" only\n",
    "model_A_clone.set_weights(model_A.get_weights()) # Set the cloned model's weight as the original one's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f1ff924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model's weights in lower layers\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4aaf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 0.1821 - accuracy: 0.9600 - val_loss: 0.1742 - val_accuracy: 0.9777\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.1431 - accuracy: 0.9750 - val_loss: 0.1457 - val_accuracy: 0.9828\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1186 - accuracy: 0.9850 - val_loss: 0.1260 - val_accuracy: 0.9848\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.1014 - accuracy: 0.9850 - val_loss: 0.1122 - val_accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "# Train a few epochs first\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "168a744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benson516/ml/my_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the model's weights in lower layers\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "optimizer = keras.optimizers.SGD(lr=1e-4) # the default lr is 1e-2\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cc64b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.0928 - accuracy: 0.9850 - val_loss: 0.1113 - val_accuracy: 0.9858\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0920 - accuracy: 0.9850 - val_loss: 0.1105 - val_accuracy: 0.9858\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.0911 - accuracy: 0.9850 - val_loss: 0.1097 - val_accuracy: 0.9858\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0903 - accuracy: 0.9850 - val_loss: 0.1089 - val_accuracy: 0.9858\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.0895 - accuracy: 0.9850 - val_loss: 0.1082 - val_accuracy: 0.9858\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0887 - accuracy: 0.9850 - val_loss: 0.1074 - val_accuracy: 0.9858\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.0879 - accuracy: 0.9850 - val_loss: 0.1067 - val_accuracy: 0.9858\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 54ms/step - loss: 0.0871 - accuracy: 0.9850 - val_loss: 0.1059 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.0864 - accuracy: 0.9850 - val_loss: 0.1051 - val_accuracy: 0.9858\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.0855 - accuracy: 0.9850 - val_loss: 0.1044 - val_accuracy: 0.9858\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0848 - accuracy: 0.9850 - val_loss: 0.1037 - val_accuracy: 0.9858\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0841 - accuracy: 0.9850 - val_loss: 0.1030 - val_accuracy: 0.9858\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.0833 - accuracy: 0.9850 - val_loss: 0.1023 - val_accuracy: 0.9858\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.0825 - accuracy: 0.9850 - val_loss: 0.1016 - val_accuracy: 0.9858\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0819 - accuracy: 0.9850 - val_loss: 0.1009 - val_accuracy: 0.9868\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0812 - accuracy: 0.9850 - val_loss: 0.1003 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# Train the rest epochs\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8972d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0965 - accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0964755117893219, 0.9904999732971191]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e923f",
   "metadata": {},
   "source": [
    "# Faster Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39060961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model_A\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55caecc4",
   "metadata": {},
   "source": [
    "## Momentum Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60bd31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ebf1ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 53s 37ms/step - loss: 0.3588 - accuracy: 0.8732 - val_loss: 0.3828 - val_accuracy: 0.8515\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6890f10",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69242616",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d5e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 30s 21ms/step - loss: 0.2613 - accuracy: 0.9089 - val_loss: 0.3071 - val_accuracy: 0.8837\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948da5b9",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "badc5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65900ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 33s 22ms/step - loss: 0.3786 - accuracy: 0.8660 - val_loss: 0.2811 - val_accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf706bb",
   "metadata": {},
   "source": [
    "## Adam and Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f12ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826944cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 269/1375 [====>.........................] - ETA: 18s - loss: 0.2922 - accuracy: 0.8931"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a12cd",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power scheduling\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f961b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential scheduling\n",
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential scheduling (functional)\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A), callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f23062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piecewise constant scheduling\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance scheduling\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A), callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras: keras.optimizers.schedules\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19635167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#                 optimizer=optimizer,\n",
    "#                 metrics=[\"accuracy\"])\n",
    "# history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "#                     validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c075fe",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization\n",
    "## l1 and l2 REgularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='elu',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense, \n",
    "                           activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\",\n",
    "                    kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce081b1",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=1,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ed69d",
   "metadata": {},
   "source": [
    "## Monte Carlo (MC) Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_A, training=True) for sample in range(10)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dfd88",
   "metadata": {},
   "source": [
    "## Max-norm Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72505d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                  kernel_constraint=keras.constraints.maax_norm(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd795de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875692de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
