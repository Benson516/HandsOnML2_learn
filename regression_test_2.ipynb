{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899fa113",
   "metadata": {},
   "source": [
    "# Regression with Different Output Format under Various Data Conditions\n",
    "\n",
    "In this experience, we test the following output format for regression task under several different data coditions.\n",
    "- Numerical output\n",
    "- Regression as classification (grid-out)\n",
    "\n",
    "The data coditions include:\n",
    "- Sparse (few data)\n",
    "- Grouped\n",
    "  - Biased (parallel data)\n",
    "  - Completely different mode, uncorrelated data (cross)\n",
    "  - Partially diversed (split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625ce7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad564ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"regression_test_2\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e8a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_func(func_in, x_min=-5, x_max=5, mark='r--', linewidth=1, label='func'):\n",
    "    n_sample = 100\n",
    "    X_func = np.linspace(x_min, x_max, n_sample).reshape(n_sample, 1)\n",
    "    y_func = func_in(X_func)\n",
    "    plt.plot(X_func, y_func, mark, linewidth=linewidth, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ffe35",
   "metadata": {},
   "source": [
    "Generate polynomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce670ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_a1 = 5.0\n",
    "# poly_a1 = -10.0 # 5.0\n",
    "#\n",
    "sin_a = 0.0\n",
    "# sin_a = 10.0\n",
    "sin_f = 0.1 # 0.2\n",
    "#\n",
    "def func_0(X): # Reference\n",
    "    return 0.5 * X**3 + 0.5 * X**2 + (poly_a1)*X + 2 + sin_a*np.sin(2.0*np.pi*sin_f*X)\n",
    "def func_1(X): # Variation 1: parellel\n",
    "    return 0.5 * X**3 + 0.5 * X**2 + (poly_a1)*X + 30 + sin_a*np.sin(2.0*np.pi*sin_f*X)\n",
    "def func_2(X): # Variation 2: cross\n",
    "    return -0.5 * X**3 + 0.5 * X**2 + (poly_a1)*X + 30 + sin_a*np.sin(2.0*np.pi*sin_f*X)\n",
    "def func_3(X): # Variation 3: slightly split\n",
    "    return 0.3 * X**3 + 1.0 * X**2 + (poly_a1)*X + 15 + sin_a*np.sin(2.0*np.pi*sin_f*X)\n",
    "def func_4(X): # Sine wave~\n",
    "    return 0.5 * X**3 + 0.5 * X**2 + (poly_a1)*X + 2 + 20.0*np.sin(2.0*np.pi*sin_f*X) # 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9463bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dict = dict()\n",
    "#-----------------#\n",
    "func_dict[\"f1\"] = func_0\n",
    "#-----------------#\n",
    "# func_dict[\"f2\"] = func_1\n",
    "# func_dict[\"f2\"] = func_2\n",
    "func_dict[\"f2\"] = func_3\n",
    "# func_dict[\"f2\"] = func_4\n",
    "#-----------------#\n",
    "func_dict[\"f3\"] = func_4\n",
    "#-----------------#\n",
    "\n",
    "# Note: func_dict[\"f_avg\"] depends on multiout_type and is calculated in each section of multiout_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63437d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(m, m_train) = (100, 80)\n",
      "y_data_pure.shape = (100, 1)\n",
      "y_data.shape = (100, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "m = 100 # 50 # 100 # 200\n",
    "m_train = m // 5 * 4\n",
    "print(\"(m, m_train) = (%d, %d)\" % (m, m_train))\n",
    "\n",
    "# Input\n",
    "is_gapped = True\n",
    "# is_gapped = False\n",
    "#\n",
    "if not is_gapped:\n",
    "    X_data = 10 * np.random.rand(m, 1) - 5 # Note: X is randomly sampled, so we don't need to shuffle the data again\n",
    "else:\n",
    "    X_data = np.concatenate( (np.linspace(-5.0, -2.0, m//2), np.linspace(2.0, 5.0, m-m//2)) )\n",
    "    X_data = X_data.reshape((m,1))\n",
    "    np.random.shuffle(X_data)\n",
    "\n",
    "# Output, multiout_type in {1, 2, 3}\n",
    "# multiout_type = 1      \n",
    "multiout_type = 2 \n",
    "# multiout_type = 3 \n",
    "#\n",
    "sid_data = np.ones((m,1), dtype=int) # subject id, default: 1\n",
    "if multiout_type == 2:\n",
    "    m_h = m // 2\n",
    "    X_data_1 = X_data[:m_h]\n",
    "    X_data_2 = X_data[m_h:]\n",
    "    sid_data[:m_h] = 1 # id:1\n",
    "    sid_data[m_h:] = 2 # id:2\n",
    "    y_data_pure_1 = func_dict[\"f1\"](X_data_1) \n",
    "    y_data_pure_2 = func_dict[\"f2\"](X_data_2) \n",
    "    y_data_pure = np.vstack([y_data_pure_1, y_data_pure_2])\n",
    "    print(\"y_data_pure.shape = %s\" % str(y_data_pure.shape))\n",
    "    # Average line\n",
    "    func_dict[\"f_avg\"] = ( lambda X: 0.5*func_dict[\"f1\"](X) + 0.5*func_dict[\"f2\"](X) )\n",
    "    #\n",
    "elif multiout_type == 3: # with \"avg\" line\n",
    "    m_t = m // 3\n",
    "    X_data_1 = X_data[:m_t]\n",
    "    X_data_2 = X_data[m_t:(2*m_t)]\n",
    "    X_data_3 = X_data[(2*m_t):]\n",
    "    sid_data[:m_t]        = 1 # id:1\n",
    "    sid_data[m_t:(2*m_t)] = 2 # id:2\n",
    "    sid_data[(2*m_t):]    = 3 # id:3\n",
    "    y_data_pure_1 = func_dict[\"f1\"](X_data_1) \n",
    "    y_data_pure_2 = func_dict[\"f2\"](X_data_2) \n",
    "    y_data_pure_3 = func_dict[\"f3\"](X_data_3) \n",
    "    y_data_pure = np.vstack([y_data_pure_1, y_data_pure_2, y_data_pure_3])\n",
    "    print(\"y_data_pure.shape = %s\" % str(y_data_pure.shape))\n",
    "    # Average line\n",
    "    func_dict[\"f_avg\"] = ( lambda X: (func_dict[\"f1\"](X) + func_dict[\"f2\"](X) + func_dict[\"f3\"](X))/3.0 )\n",
    "    #\n",
    "else: # multiout_type == 1\n",
    "    # Average line\n",
    "    func_dict[\"f_avg\"] = ( lambda X: 0.5*func_dict[\"f1\"](X) + 0.5*func_dict[\"f2\"](X) )\n",
    "    y_data_pure = func_dict[\"f_avg\"](X_data)\n",
    "\n",
    "    \n",
    "# Label (+noise)\n",
    "n_stddev = 2.0\n",
    "# n_stddev = 10.0\n",
    "y_data = y_data_pure + np.random.randn(m, 1) * n_stddev\n",
    "print(\"y_data.shape = %s\" % str(y_data.shape))\n",
    "# print(\"sid_data = %s\" % str(sid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef588fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: simply slice\n",
    "# X_train = X_data[:m_train]\n",
    "# y_train = y_data[:m_train]\n",
    "# X_valid = X_data[m_train:]\n",
    "# y_valid = y_data[m_train:]\n",
    "\n",
    "# Method 2: shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid, sid_train, sid_valid = train_test_split(X_data, y_data, sid_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5d2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# print(\"sid_train = %s\" % str(sid_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd2136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_normal_func(func_dict):\n",
    "    if multiout_type != 1:\n",
    "        draw_func(func_dict[\"f1\"], mark='c:', label=\"f1\")\n",
    "        draw_func(func_dict[\"f2\"], mark='r:', label=\"f2\")\n",
    "    if multiout_type == 3:\n",
    "        draw_func(func_dict[\"f3\"], mark='y:', label=\"f3\")\n",
    "    draw_func(func_dict[\"f_avg\"], mark='m--', label=\"f_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4283c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(X, y, sid=None):\n",
    "    if sid is None:\n",
    "        plt.plot(X, y, \"b.\")\n",
    "    else:\n",
    "        plt.plot(X[sid==1], y[sid==1], \"b.\")\n",
    "        plt.plot(X[sid==2], y[sid==2], \"r.\")\n",
    "        plt.plot(X[sid==3], y[sid==3], \"y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693af3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure training_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "# plt.plot(X_train[sid_train==1], y_train[sid_train==1], \"b.\")\n",
    "# plt.plot(X_train[sid_train==2], y_train[sid_train==2], \"r.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"training_data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6853ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_error_dict = dict()\n",
    "\n",
    "def get_prediction_error(func_in, func_dict, name=\"\", x_min=-5, x_max=5, prediction_error_dict=prediction_error_dict):\n",
    "    n_sample = 100\n",
    "    X_func = np.linspace(x_min, x_max, n_sample).reshape(n_sample, 1)\n",
    "    y_func = func_in(X_func).reshape((n_sample,1))\n",
    "    y_gt = func_dict[\"f_avg\"](X_func).reshape((n_sample,1))\n",
    "    print(\"y_func.shape = %s\" % str(y_func.shape))\n",
    "    print(\"y_gt.shape = %s\" % str(y_gt.shape))\n",
    "#     total_error = np.sqrt(np.square(y_func - y_gt).mean())\n",
    "    total_error = np.abs(y_func - y_gt).mean()\n",
    "    prediction_error_dict[name] = total_error\n",
    "    return total_error\n",
    "\n",
    "def print_all_prediction_error(is_logging_to_screen=True, prediction_error_dict=prediction_error_dict):\n",
    "    _s = \"\"\n",
    "    for _n in prediction_error_dict:\n",
    "        _s += (\"%s: %f\" % (_n, prediction_error_dict[_n])) + \"\\n\"\n",
    "    if is_logging_to_screen:\n",
    "        print(_s)\n",
    "    return _s\n",
    "        \n",
    "def save_prediction_errors(is_logging_to_screen=False, prediction_error_dict=prediction_error_dict):\n",
    "    path = os.path.join(IMAGES_PATH, \"prediction_errors.txt\")\n",
    "    print(\"Saving all prediction errors to [%s].\" % path)\n",
    "    _s = print_all_prediction_error(is_logging_to_screen=is_logging_to_screen, prediction_error_dict=prediction_error_dict)\n",
    "    with open(path, \"w\") as _f:\n",
    "        _f.write(_s)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ecc57",
   "metadata": {},
   "source": [
    "# Simple FCs (number --> number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66eb67b",
   "metadata": {},
   "source": [
    "Build the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9449fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ad59bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Customized loss function\n",
    "# def asymptoticLoss_fn(y_true, y_pred, alpha=0.01):\n",
    "#     # tau: quantile, tau in [0.0, 1.0]\n",
    "#     # y_true: label mean\n",
    "#     # y_pred: predicted tau quantile\n",
    "#     y_target = alpha * y_true + (1.0 - alpha) * y_pred\n",
    "#     # return tf.abs(y_pred - y_target)\n",
    "#     return (y_pred - y_target)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de396a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benso\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "# optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "# # model.compile(loss=\"mean_absolute_error\", optimizer=optimizer)\n",
    "# model.compile(loss=asymptoticLoss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afd68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 2482.7036 - val_loss: 1687.5508\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2397.8794 - val_loss: 1602.8322\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2235.3794 - val_loss: 1435.3951\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1874.0433 - val_loss: 1046.3013\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 999.3638 - val_loss: 511.6038\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 626.2381 - val_loss: 1008.5215\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 919.8281 - val_loss: 378.8942\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 377.3785 - val_loss: 507.8655\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 746.8472 - val_loss: 401.3120\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 471.5699 - val_loss: 171.6577\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 253.4529 - val_loss: 368.7628\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 452.7078 - val_loss: 182.4047\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 269.0383 - val_loss: 217.0364\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 289.8980 - val_loss: 197.8270\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 216.4272 - val_loss: 210.1378\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 237.3228 - val_loss: 220.8410\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 222.4846 - val_loss: 185.3737\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 203.1293 - val_loss: 182.6527\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 215.3995 - val_loss: 172.3740\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 201.2121 - val_loss: 174.6239\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 202.7721 - val_loss: 174.3378\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 201.6553 - val_loss: 171.0564\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 198.1998 - val_loss: 176.1044\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 201.1637 - val_loss: 185.5870\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 196.4934 - val_loss: 185.8341\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 196.5439 - val_loss: 180.6968\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 195.2314 - val_loss: 174.1455\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 191.6704 - val_loss: 171.5133\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 191.9554 - val_loss: 169.8391\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 191.6653 - val_loss: 167.6271\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 192.1855 - val_loss: 168.4670\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 189.5112 - val_loss: 166.8493\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 189.6178 - val_loss: 166.7837\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 188.8284 - val_loss: 168.1707\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 188.4311 - val_loss: 168.4503\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 187.9485 - val_loss: 167.7908\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 188.0346 - val_loss: 170.5434\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 186.2430 - val_loss: 171.9736\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 186.2748 - val_loss: 173.2025\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 188.5739 - val_loss: 172.0308\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 185.0457 - val_loss: 167.1906\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 185.9814 - val_loss: 164.5621\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 185.6371 - val_loss: 161.8201\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 183.3795 - val_loss: 163.4839\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 183.2449 - val_loss: 167.8580\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 182.1930 - val_loss: 168.0625\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 182.0727 - val_loss: 164.6106\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 181.2102 - val_loss: 162.8971\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 181.1946 - val_loss: 163.2679\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 179.4284 - val_loss: 169.8251\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 181.7545 - val_loss: 172.1881\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 179.2229 - val_loss: 169.4094\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 180.9034 - val_loss: 166.0722\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 179.8265 - val_loss: 163.1953\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 177.1573 - val_loss: 163.0690\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 176.3679 - val_loss: 162.5305\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 175.4173 - val_loss: 160.8184\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 179.3832 - val_loss: 158.2482\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 176.7953 - val_loss: 161.2379\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 174.0838 - val_loss: 163.3469\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 174.1824 - val_loss: 164.7334\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 173.7886 - val_loss: 163.4711\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 174.1061 - val_loss: 163.4748\n",
      "Epoch 64/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 152.9826"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6e37a",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b066f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"num_num_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "# y_new = model.predict(X_new)\n",
    "#\n",
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "# plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "draw_func(model.predict, mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"num_num_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error(model.predict, func_dict, name=\"num-num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da8768",
   "metadata": {},
   "source": [
    "# Simulated CNN Feature Map (1-D grids, grid --> number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class num2grid(keras.layers.Layer):\n",
    "    def __init__(self, units, x_min=-10, x_max=10, sigma=1.0, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.sigma = sigma\n",
    "        self.sigma2 = self.sigma**2\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        #\n",
    "        self.x_grid = np.linspace(self.x_min, self.x_max, self.units, endpoint=True)\n",
    "#         print(\"self.x_grid.shape = %s\" % str(self.x_grid.shape))\n",
    "        #\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "        \n",
    "    def call(self, X):\n",
    "        '''\n",
    "        Input shape:  (batch, X_chanel)\n",
    "        Output shape: (batch, grid_unit) \n",
    "        \n",
    "        self.x_grid shape: (grid_unit,)\n",
    "        '''\n",
    "        gauss_grid = tf.exp( -(self.x_grid - X)**2 / (2.0*self.sigma2) )\n",
    "        print(\"X.shape = %s\" % str(X.shape))\n",
    "        print(\"gauss_grid.shape = %s\" % str(gauss_grid.shape))\n",
    "        return self.activation(gauss_grid)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \n",
    "                \"units\": self.units,\n",
    "                \"x_min\": self.x_min,\n",
    "                \"x_max\": self.x_max,\n",
    "                \"sigma\": self.sigma,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    num2grid(5,x_min=-10, x_max=10, sigma=3.0, input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "#     keras.layers.Dense(30, activation=keras.layers.LeakyReLU(alpha=0.2) ),\n",
    "#     keras.layers.Dense(30, activation=\"selu\"),\n",
    "#     keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Customized loss function\n",
    "# def asymptoticLoss_fn(y_true, y_pred, alpha=0.01):\n",
    "#     # tau: quantile, tau in [0.0, 1.0]\n",
    "#     # y_true: label mean\n",
    "#     # y_pred: predicted tau quantile\n",
    "#     y_target = alpha * y_true + (1.0 - alpha) * y_pred\n",
    "#     # return tf.abs(y_pred - y_target)\n",
    "#     return (y_pred - y_target)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "# optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "# # model.compile(loss=\"mean_absolute_error\", optimizer=optimizer)\n",
    "# model.compile(loss=asymptoticLoss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966ada4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d550f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_num_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "# y_new = model.predict(X_new)\n",
    "#\n",
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "# plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "draw_func(model.predict, mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_num_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c053a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error(model.predict, func_dict, name=\"grid-num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65d614",
   "metadata": {},
   "source": [
    "# Grid & Regression by Classification (grid --> grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class num2grid_np():\n",
    "    def __init__(self, units, x_min=-10, x_max=10, sigma=1.0):\n",
    "        self.units = units\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.sigma = sigma\n",
    "        self.sigma2 = self.sigma**2\n",
    "        self.x_grid = np.linspace(self.x_min, self.x_max, self.units, endpoint=True)\n",
    "        print(\"self.x_grid = %s\" % str(self.x_grid))\n",
    "        \n",
    "    def convert(self, X):\n",
    "        gauss_grid = np.exp( -(self.x_grid - X)**2 / (2.0*self.sigma2) )\n",
    "#         if len(gauss_grid.shape) == 1:\n",
    "#             gauss_grid = gauss_grid.reshape([1,-1])\n",
    "#         grid_sum = np.sum(gauss_grid, axis=1, keepdims=True)\n",
    "        grid_sum = np.sum(gauss_grid, axis=-1, keepdims=True)\n",
    "        gauss_grid = gauss_grid / grid_sum\n",
    "        return gauss_grid\n",
    "    \n",
    "    def inv_convert(self, grid):\n",
    "#         if len(grid.shape) == 1:\n",
    "#             grid = grid.reshape([1,-1])\n",
    "#         grid_sum = np.sum(grid, axis=1)\n",
    "        grid_sum = np.sum(grid, axis=-1)\n",
    "#         print(grid_sum)\n",
    "        exp_num = np.sum((self.x_grid * grid), axis=-1) / grid_sum # element-wise\n",
    "        return exp_num\n",
    "    \n",
    "    def get_statistic(self, grid):\n",
    "        grid_sum = np.sum(grid, axis=-1)\n",
    "        _mean = np.sum((self.x_grid * grid), axis=-1) / grid_sum # element-wise\n",
    "        _var  = np.sum( ((self.x_grid.reshape((1,-1)) - _mean.reshape((-1,1)))**2 * grid), axis=-1) / grid_sum # element-wise\n",
    "        # print(\"(_mean, _var) = (%f, %f)\" % (_mean, _var))\n",
    "        _stddev = np.sqrt(_var)\n",
    "        return _mean, _stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_num = 10 # 10\n",
    "# n2g = num2grid_np(class_num, x_min=-100.0, x_max=100.0, sigma=20.0) # 20.0\n",
    "# class_num = 20\n",
    "# n2g = num2grid_np(class_num, x_min=-100.0, x_max=100.0, sigma=15.0) # 20.0\n",
    "class_num = 50\n",
    "n2g = num2grid_np(class_num, x_min=-100.0, x_max=100.0, sigma=6.0) # 5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce05258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_1 = n2g.convert(-1.2)\n",
    "grid_1 = n2g.convert([[-1.2]])\n",
    "print(grid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48203fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2g.inv_convert(grid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2g.get_statistic(grid_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0b9a0",
   "metadata": {},
   "source": [
    "### Convert the labels to grid (pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_grid = n2g.convert(y_train)\n",
    "y_valid_grid = n2g.convert(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_grid.shape)\n",
    "print(y_valid_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71610af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    num2grid(5,x_min=-10, x_max=10, sigma=3.0, input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "    keras.layers.Dense(class_num, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2244aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train_grid, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390834c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_rbc_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "# y_new_proba = model.predict(X_new)\n",
    "# y_new = n2g.inv_convert(y_new_proba)\n",
    "#\n",
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "# plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "draw_func((lambda X: n2g.inv_convert(model.predict(X)) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_rbc_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc059ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error((lambda X: n2g.inv_convert(model.predict(X)) ), func_dict, name=\"grid-rbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.linspace(-5, 5, 100).reshape(100, 1)\n",
    "y_new_proba = model.predict(X_new)\n",
    "# y_new = n2g.inv_convert(y_new_proba)\n",
    "#\n",
    "xv, yv = np.meshgrid(X_new, np.linspace(n2g.x_min, n2g.x_max, n2g.units))\n",
    "# print(xv)\n",
    "# print(yv)\n",
    "plt.pcolormesh(xv, yv, y_new_proba.T, shading=\"nearest\")\n",
    "save_fig(\"grid_rbc_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064d3b5",
   "metadata": {},
   "source": [
    "### Draw the 1-sigma boundary line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sigma_boundary_line(X, n):\n",
    "    _mean, _sigma = n2g.get_statistic(model.predict(X))\n",
    "    return( _mean + n*_sigma)\n",
    "\n",
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "#\n",
    "draw_func((lambda X: n2g.inv_convert(model.predict(X)) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_func((lambda X: n_sigma_boundary_line(X, +1.0) ), mark='k--', linewidth=1, label=\"$\\mu+\\sigma$\")\n",
    "draw_func((lambda X: n_sigma_boundary_line(X, -1.0) ), mark='k--', linewidth=1, label=\"$\\mu-\\sigma$\")\n",
    "#\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_rbc_prediction_1sigma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6266336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a85ab5",
   "metadata": {},
   "source": [
    "# Grid & Regression by Classification + Offset Estimation (grid --> grid,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26440167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class num2gridOffset_np():\n",
    "    def __init__(self, units, x_min=-10, x_max=10):\n",
    "        self.units = units\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.x_grid = np.linspace(self.x_min, self.x_max, self.units, endpoint=True)\n",
    "        # bins\n",
    "        x_space = np.average(self.x_grid[1:] - self.x_grid[:-1])\n",
    "        print(\"x_space = %f\" % x_space)\n",
    "        x_0 = self.x_grid[0] - 0.5 * x_space\n",
    "        self.x_bins = [x_0 + _i*x_space for _i in range(len(self.x_grid)+1)]\n",
    "        print(\"self.x_grid = %s\" % str(self.x_grid))\n",
    "#         print(\"self.x_bins = %s\" % str(self.x_bins))\n",
    "        \n",
    "    def convert(self, X):\n",
    "        '''\n",
    "        Convert a batch of number to one-hot class and numerical offset to each grid's center\n",
    "        (m, 1) --> (m, n_units, 2)\n",
    "        '''\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) <= 1:\n",
    "            X = X.reshape((-1,1))\n",
    "        idxs_bin = np.digitize(X, self.x_bins, right=False) \n",
    "        idxs_grid = (idxs_bin - 1) + 1*(idxs_bin<= 0) - 1*(idxs_bin>=self.units)\n",
    "        print(idxs_grid.shape)\n",
    "        #\n",
    "        batch_size = X.shape[0]\n",
    "        grid = np.zeros((batch_size, self.units, 2))\n",
    "        # Fill in the values\n",
    "        grid[np.arange(batch_size), idxs_grid.reshape((-1,)), 0] = 1.0\n",
    "        grid[np.arange(batch_size), :, 1] = X - self.x_grid.reshape((1,-1)) # Offset\n",
    "        return grid\n",
    "    \n",
    "    def inv_convert(self, grid):\n",
    "        idxs_grid = np.argmax(grid[...,0], axis=1)\n",
    "        print(idxs_grid.shape)\n",
    "        #\n",
    "        batch_size = grid.shape[0]\n",
    "        offset_est = grid[np.arange(batch_size),idxs_grid,1]\n",
    "        print(offset_est.shape)\n",
    "        num_est = self.x_grid[idxs_grid].reshape((1,-1)) + offset_est\n",
    "        return num_est.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 10 # 10\n",
    "n2go = num2gridOffset_np(class_num, x_min=-100.0, x_max=100.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_1 = n2g.convert(-1.2)\n",
    "grid_1 = n2go.convert([[-1.2], [50.5]])\n",
    "print(grid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48840dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2go.inv_convert(grid_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11683cea",
   "metadata": {},
   "source": [
    "### Convert the labels to grid (pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472997cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_grid_offset = n2go.convert(y_train)\n",
    "y_valid_grid_offset = n2go.convert(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f08d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_grid_offset.shape)\n",
    "print(y_valid_grid_offset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=X_train.shape[1:])\n",
    "#\n",
    "z = num2grid(5,x_min=-10, x_max=10, sigma=3.0)(inputs)\n",
    "z = keras.layers.Dense(30, activation=\"selu\")(z)\n",
    "# Outputs\n",
    "z_proba = keras.layers.Dense(30, activation=\"relu\")(z)\n",
    "z_proba  = keras.layers.Dense(class_num, activation=\"softmax\")(z_proba)\n",
    "z_offset = keras.layers.Dense(class_num, activation=\"relu\")(z)\n",
    "z_offset = keras.layers.Dense(class_num)(z_offset)\n",
    "# Concatenate\n",
    "z_proba  = keras.layers.Reshape([class_num,1])(z_proba)\n",
    "z_offset = keras.layers.Reshape([class_num,1])(z_offset)\n",
    "out_cat = keras.layers.Concatenate(axis=-1)([z_proba, z_offset])\n",
    "#\n",
    "# Models for trainig and real usage\n",
    "model = keras.Model(inputs=[inputs], outputs=[out_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6482574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function\n",
    "\n",
    "cce = keras.losses.CategoricalCrossentropy(reduction=keras.losses.Reduction.NONE)\n",
    "# cce(y_true, y_pred).numpy()\n",
    "\n",
    "def centerLoss_fn(y_true, y_pred):\n",
    "    #\n",
    "    y_true_proba = y_true[...,0]\n",
    "    y_true_value = y_true[...,1]\n",
    "    #\n",
    "    y_pred_proba = y_pred[...,0]\n",
    "    y_pred_value = y_pred[...,1]\n",
    "    \n",
    "    #\n",
    "    cce_loss = cce(y_true_proba, y_pred_proba) / class_num\n",
    "    #\n",
    "    y_true_value_est = tf.reduce_sum((y_true_proba * y_true_value), axis=-1)\n",
    "    y_pred_value_est = tf.reduce_sum((y_true_proba * y_pred_value), axis=-1)\n",
    "#     y_pred_value_est = tf.reduce_sum((y_pred_proba * y_pred_value), axis=-1)\n",
    "    value_loss = tf.abs(y_pred_value_est - y_true_value_est)\n",
    "    \n",
    "    # Total loss\n",
    "#     return (0.5*cce_loss + 0.5*value_loss )\n",
    "    return (0.2*cce_loss + 0.8*value_loss )\n",
    "#     return (cce_loss)\n",
    "#     return (value_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60575755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9)\n",
    "optimizer = keras.optimizers.Adam(lr=0.05)\n",
    "model.compile(loss=centerLoss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc47a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train_grid_offset, epochs=100,\n",
    "#                     validation_data=(X_valid, y_valid_grid_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "# plt.grid(True)\n",
    "# # plt.gca().set_ylim(0, 1)\n",
    "# save_fig(\"grid_rbcOffset_training_curve\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db8336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # plt.plot(X_train, y_train, \"b.\")\n",
    "# draw_points(X_train, y_train, sid_train)\n",
    "# draw_func((lambda X: n2go.inv_convert(model.predict(X)) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "# draw_normal_func(func_dict)\n",
    "# plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "# plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# # plt.axis([-3, 3, 0, 10])\n",
    "# save_fig(\"grid_rbcOffset_prediction\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_prediction_error((lambda X: n2go.inv_convert(model.predict(X)) ), func_dict, name=\"grid-classOffset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff995a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a811f344",
   "metadata": {},
   "source": [
    "# Parametric Uncertainty/Distribution Estimation\n",
    "\n",
    "In this section, we try to estimate uncertainty (actually, fit the dataset distribution) with parametric reprecentation of a distribution instead of a discretized non-parametric representation.\n",
    "\n",
    "Possible solution includes\n",
    "- Quantile estimation with pinball loss (statistic)\n",
    "- Guassian distribution (fit a prabability distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175eb32d",
   "metadata": {},
   "source": [
    "## Quantile Estimation with Pinball Loss (grid --> parameters)\n",
    "\n",
    "Quantile estimation and pinball loss is based on the concept of statistic, which predict the value based on the rank of samples in the dataset.\n",
    "\n",
    "The outputs of the model are $(y_{10}, y_{90})$, 10% quantile prediction and 90% quantile prediction, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ef92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile_list = [0.5]\n",
    "# quantile_list = [0.9]\n",
    "quantile_list = [0.1, 0.9] # Use hidden layer with 30 neurons\n",
    "# quantile_list = [0.05, 0.95]\n",
    "# quantile_list = [0.25, 0.75]\n",
    "# quantile_list = [0.1, 0.5, 0.9]\n",
    "# quantile_list = [0.1, 0.3, 0.7, 0.9]\n",
    "# quantile_list = [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9] # remove 0.5\n",
    "# quantile_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # Should use wider hidden layer (with many neurons) + L1 regularization\n",
    "num_quantile = len(quantile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fe57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    num2grid(5,x_min=-10, x_max=10, sigma=3.0, input_shape=X_train.shape[1:]), # Convert to grids\n",
    "#     num2grid(50,x_min=-10, x_max=10, sigma=0.5, input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "#     keras.layers.Dense(60, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"selu\", kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "#     keras.layers.Dense(100, activation=keras.layers.LeakyReLU(alpha=0.2), kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "#     keras.layers.Dense(30, activation=keras.layers.LeakyReLU(alpha=0.2) ),\n",
    "#     keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(num_quantile) # (y10, y90)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf131dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function\n",
    "def pinballLoss_fn(y_true, y_pred, tau):\n",
    "    # tau: quantile, tau in [0.0, 1.0]\n",
    "    # y_true: label mean\n",
    "    # y_pred: predicted tau quantile\n",
    "    _q = y_true - y_pred\n",
    "    return tf.math.maximum( (tau*_q), ((tau-1.0)*_q))\n",
    "    \n",
    "def pinballLoss_10_90_fn(y_true, y_pred):\n",
    "    #\n",
    "    return pinballLoss_fn(y_true, y_pred[:,0:1], 0.1) + pinballLoss_fn(y_true, y_pred[:,1:2], 0.9)\n",
    "\n",
    "def pinballLoss_full_fn(y_true, y_pred):\n",
    "    #\n",
    "    pinball_losses = tf.stack( [pinballLoss_fn(y_true, y_pred[:, _i:(_i+1)], _tau) for _i, _tau in enumerate(quantile_list)], axis=1)\n",
    "    return tf.reduce_sum(pinball_losses, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71305d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9)\n",
    "optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "# model.compile(loss=pinballLoss_10_90_fn, optimizer=optimizer)\n",
    "model.compile(loss=pinballLoss_full_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935c409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa5656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_quantile_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a59dd6",
   "metadata": {},
   "source": [
    "### Draw the mean prediction curve averaged from all quantile predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "# draw_func((lambda X: model.predict(X)[:,0] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (quantile_list[0]*100))\n",
    "# draw_func((lambda X: model.predict(X)[:,-1] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (quantile_list[-1]*100))\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_quantile_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error((lambda X: np.average(model.predict(X), axis=-1) ), func_dict, name=\"grid-quantileR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ac920",
   "metadata": {},
   "source": [
    "### Draw first and last quantile curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eeb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_func((lambda X: model.predict(X)[:,0] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (quantile_list[0]*100))\n",
    "draw_func((lambda X: model.predict(X)[:,-1] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (quantile_list[-1]*100))\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_quantile_boundary_quantiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b1b44",
   "metadata": {},
   "source": [
    "### Draw all quantile predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e875238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "for _idx, _tau in enumerate(quantile_list):\n",
    "    draw_func((lambda X: model.predict(X)[:,_idx] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (_tau*100))\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_quantile_all_quantiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693a8eb",
   "metadata": {},
   "source": [
    "### Multi-Quantiles as a Gaussian Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11262fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def n_sigma_boundary_line(X, n):\n",
    "#     _y = model.predict(X)\n",
    "#     _mean = np.mean(_y, axis=-1)\n",
    "#     _sigma = np.std(_y, axis=-1)\n",
    "#     return( _mean + n*_sigma)\n",
    "\n",
    "# # plt.plot(X_train, y_train, \"b.\")\n",
    "# draw_points(X_train, y_train, sid_train)\n",
    "# #\n",
    "# draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "# draw_func((lambda X: n_sigma_boundary_line(X, +1.0) ), mark='k--', linewidth=1, label=\"$\\mu+\\sigma$\")\n",
    "# draw_func((lambda X: n_sigma_boundary_line(X, -1.0) ), mark='k--', linewidth=1, label=\"$\\mu-\\sigma$\")\n",
    "# #\n",
    "# draw_normal_func(func_dict)\n",
    "# plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "# plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# # plt.axis([-3, 3, 0, 10])\n",
    "# save_fig(\"grid_quantile_1sigma\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01aa69",
   "metadata": {},
   "source": [
    "## Gaussian Estimation with Gaussian Loss (grid-->parameters)\n",
    "\n",
    "Gaussain estimation requires the model to predict the mean and variance of a Gaussian distribution of the random variable regarded. The training purpose is to fit a Gaussian distribution to the data distribution (which is not necessay distributed as Gaussian).\n",
    "\n",
    "One possible solution, derived by BensonHuang, is that the model estimates $(\\mu, z)$, where $z=\\alpha ^{-1}log(\\sigma)$.\n",
    "The associated loss function can be $L_G(y, (\\mu,z)) = 0.5e^{-2\\alpha z}(y-\\mu)^2 + \\alpha z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "# alpha = 0.01\n",
    "# alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb202ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    num2grid(5,x_min=-10, x_max=10, sigma=3.0, input_shape=X_train.shape[1:]),\n",
    "#     keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(60, activation=\"relu\"),\n",
    "#     keras.layers.Dense(30, activation=keras.layers.LeakyReLU(alpha=0.2) ),\n",
    "#     keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(2) # (mu, z)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized loss function\n",
    "print(\"alpha = %f\" % alpha)\n",
    "\n",
    "def GaussianLoss_fn(y_true, y_pred):\n",
    "    # y_true: label \n",
    "    # y_pred: (mu, z), z=log(sigma)\n",
    "    mu = y_pred[:, 0:1]\n",
    "    z  = y_pred[:, 1:2]\n",
    "    #\n",
    "    en2z = tf.math.exp((-2.0*alpha)*z)\n",
    "    ymu2 = (y_true - mu)**2\n",
    "    return (0.5*en2z*ymu2 + alpha*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b388b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "learning_rate_switch_epoch_list = [30, 45]\n",
    "learning_rate_list = [0.001, 0.01, 0.1]\n",
    "# learning_rate_switch_epoch_list = [30, 80]\n",
    "# learning_rate_list = [0.01, 0.1, 0.01]\n",
    "#\n",
    "def piecewise_constant_fn(epoch):\n",
    "    for _i, epoch_s in enumerate(learning_rate_switch_epoch_list):\n",
    "        if epoch < epoch_s:\n",
    "            return learning_rate_list[_i]\n",
    "    return learning_rate_list[-1]\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2e05e",
   "metadata": {},
   "source": [
    "Third training with even greater speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9)\n",
    "optimizer = keras.optimizers.Adam(lr=0.1) # 0.1\n",
    "model.compile(loss=GaussianLoss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b74a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29d35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=145,\n",
    "#                     validation_data=(X_valid, y_valid), callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28215732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# print(history.history)\n",
    "try:\n",
    "    lr_list = history.history[\"lr\"]\n",
    "    del(history.history[\"lr\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pd.DataFrame(history.history)[50:].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_Gaussian_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d362c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: model.predict(X)[:,0] ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_Gaussian_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error((lambda X: model.predict(X)[:,0] ), func_dict, name=\"grid-oneGaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1e36d",
   "metadata": {},
   "source": [
    "### Draw the 1-sigma boundary line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sigma_boundary_line(X, n):\n",
    "    _y = model.predict(X)\n",
    "    _mean, _z = _y[:,0:1], _y[:,1:2]\n",
    "    _sigma = np.exp(alpha*_z)\n",
    "    return( _mean + n*_sigma)\n",
    "\n",
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "#\n",
    "draw_func((lambda X: model.predict(X)[:,0] ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_func((lambda X: n_sigma_boundary_line(X, +1.0) ), mark='k--', linewidth=1, label=\"$\\mu+\\sigma$\")\n",
    "draw_func((lambda X: n_sigma_boundary_line(X, -1.0) ), mark='k--', linewidth=1, label=\"$\\mu-\\sigma$\")\n",
    "#\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_Gaussian_1sigma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb8a83",
   "metadata": {},
   "source": [
    "# Per-subject Bias/Property Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a429b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer for estimating bais for each subject\n",
    "class SubjectBias(keras.layers.Layer):\n",
    "    def __init__(self, num_subject, bias_scale=1.0, mean_reg_rate=1.0, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_subject = num_subject\n",
    "        self.bias_scale = bias_scale\n",
    "        self.mean_reg_rate = mean_reg_rate if mean_reg_rate >= 0.0 else 0.0\n",
    "        #\n",
    "        self.X_shape = None\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.X_shape = batch_input_shape[0]\n",
    "        # Initiate a trainable vector as the bias for X\n",
    "        \"\"\"\n",
    "        bias: (num_subject, X_shape[1], X_shape[2], ...)\n",
    "        \"\"\"\n",
    "        self.bias = self.add_weight(name=\"bias\", \n",
    "                                    shape=([self.num_subject] + self.X_shape[1:]), \n",
    "                                    initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "        \n",
    "    def get_bias(self, sid):\n",
    "        '''\n",
    "        A helper function for retriving the bias according to the given sid.\n",
    "        Note: sid starts from 1.\n",
    "        Note2: this is the bias added to X, which are scaled by self.bias_scale\n",
    "        '''\n",
    "        if sid > self.num_subject or sid <= 0: # Out of bound, index not in range\n",
    "            return tf.zeros(self.X_shape[1:])\n",
    "        else:\n",
    "            return self.bias_scale * self.bias[tf.cast(sid-1, tf.int32),:]\n",
    "        \n",
    "    def get_scaled_biases_np(self):\n",
    "        return self.bias_scale * self.bias.numpy()\n",
    "        \n",
    "    def call(self, X_sid, training=None):\n",
    "        '''\n",
    "        X_sid = [X, sid]\n",
    "        Input shape:  X: (batch, ...), sid: (batch, 1)\n",
    "        Output shape: (batch, ...)\n",
    "        '''\n",
    "        X, SID = X_sid\n",
    "        X_shape = X.shape\n",
    "        print(\"X.shape = %s\" % X.shape)\n",
    "        print(\"SID.shape = %s\" % SID.shape)\n",
    "        \n",
    "        # Add bias\n",
    "        y = X + self.bias_scale * tf.gather(self.bias, SID[:,0]-1, axis=0)\n",
    "        \n",
    "        # Add a loss on the means in order to force them to become zeros\n",
    "        if self.mean_reg_rate > 0.0:\n",
    "            # Calculate the mean of all biases (on each dimension)\n",
    "            bias_means = tf.reduce_mean(self.bias, axis=0)\n",
    "            # MAE of means on all dimensions\n",
    "            self.add_loss( self.mean_reg_rate * tf.reduce_sum(tf.abs(bias_means)) )\n",
    "        \n",
    "        return self.activation(y)\n",
    "        \n",
    "#         if training:    \n",
    "#             # Add biases according to the sid of each instance\n",
    "#             # Note: a corner case is not handeled that if there exist out-of-range sid.\n",
    "#             # y = X + self.bias[tf.cast(SID[:,0]-1, tf.int32),:]\n",
    "#             # y = X + self.bias[ SID[:,0]-1,:]\n",
    "#             y = X + tf.gather(self.bias, SID[:,0]-1, axis=0)\n",
    "#             return self.activation(y)\n",
    "#         else: # If it's not trainig, just output the original X without adding bias\n",
    "#             return self.activation(X_sid[0])\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        # Note: the same shape as the first input\n",
    "        return batch_input_shape[0]\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \n",
    "                \"num_subject\": self.num_subject,\n",
    "                \"bias_scale\": self.bias_scale,\n",
    "                \"mean_reg_rate\": self.mean_reg_rate,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer for estimating linear transform for each subject\n",
    "# We only assume 1D lear transform on each input dimension separately. (assume value on each dimension are independent to others.)\n",
    "# 1D linear transform: yi = wi * xi + bi\n",
    "class SubjectLinearTransform1D(keras.layers.Layer):\n",
    "    def __init__(self, num_subject, bias_scale=1.0, weight_mean_reg_rate=1.0, bias_mean_reg_rate=1.0, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_subject = num_subject\n",
    "        self.bias_scale = bias_scale\n",
    "        self.weight_mean_reg_rate = weight_mean_reg_rate if weight_mean_reg_rate >= 0.0 else 0.0\n",
    "        self.bias_mean_reg_rate = bias_mean_reg_rate if bias_mean_reg_rate >= 0.0 else 0.0\n",
    "        #\n",
    "        self.X_shape = None\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.X_shape = batch_input_shape[0]\n",
    "        # Initiate a trainable vector as the bias for X\n",
    "        \"\"\"\n",
    "        bias: (num_subject, X_shape[1], X_shape[2], ...)\n",
    "        \"\"\"\n",
    "        self.weight = self.add_weight(name=\"weight\", \n",
    "                                    shape=([self.num_subject] + self.X_shape[1:]), \n",
    "                                    initializer=\"ones\")\n",
    "        self.bias = self.add_weight(name=\"bias\", \n",
    "                                    shape=([self.num_subject] + self.X_shape[1:]), \n",
    "                                    initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "        \n",
    "    def get_bias(self, sid):\n",
    "        '''\n",
    "        A helper function for retriving the bias according to the given sid.\n",
    "        Note: sid starts from 1.\n",
    "        Note2: this is the bias added to X, which are scaled by self.bias_scale\n",
    "        '''\n",
    "        if sid > self.num_subject or sid <= 0: # Out of bound, index not in range\n",
    "            return tf.zeros(self.X_shape[1:])\n",
    "        else:\n",
    "            return self.bias_scale * self.bias[tf.cast(sid-1, tf.int32),:]\n",
    "        \n",
    "    def get_scaled_biases_np(self):\n",
    "        return self.bias_scale * self.bias.numpy()\n",
    "    \n",
    "    def get_weights_np(self):\n",
    "        return self.weight.numpy()\n",
    "        \n",
    "    def call(self, X_sid, training=None):\n",
    "        '''\n",
    "        X_sid = [X, sid]\n",
    "        Input shape:  X: (batch, ...), sid: (batch, 1)\n",
    "        Output shape: (batch, ...)\n",
    "        '''\n",
    "        X, SID = X_sid\n",
    "        X_shape = X.shape\n",
    "        print(\"X.shape = %s\" % X.shape)\n",
    "        print(\"SID.shape = %s\" % SID.shape)\n",
    "        \n",
    "        # Element-wise multiplication of weights and addition of biases\n",
    "        y = tf.gather(self.weight, SID[:,0]-1, axis=0) * X + self.bias_scale * tf.gather(self.bias, SID[:,0]-1, axis=0)\n",
    "        \n",
    "        # Add a loss on the means in order to force them to become zeros\n",
    "        if self.weight_mean_reg_rate > 0.0 or self.bias_mean_reg_rate > 0.0:\n",
    "            # Calculate the mean of all weights and biases (on each dimension separately)\n",
    "            weight_means = tf.reduce_mean(self.weight, axis=0)\n",
    "            bias_means = tf.reduce_mean(self.bias, axis=0)\n",
    "            # MAE of means on all dimensions\n",
    "            self.add_loss( self.weight_mean_reg_rate * tf.reduce_sum(tf.abs(weight_means - 1.0)) ) # Should close to 1.0\n",
    "            self.add_loss( self.bias_mean_reg_rate * tf.reduce_sum(tf.abs(bias_means)) )\n",
    "        \n",
    "        return self.activation(y)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        # Note: the same shape as the first input\n",
    "        return batch_input_shape[0]\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \n",
    "                \"num_subject\": self.num_subject,\n",
    "                \"bias_scale\": self.bias_scale,\n",
    "                \"weight_mean_reg_rate\": self.weight_mean_reg_rate,\n",
    "                \"bias_mean_reg_rate\": self.bias_mean_reg_rate,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00220bd0",
   "metadata": {},
   "source": [
    "Number of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa925d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of subjects\n",
    "num_subject = multiout_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e02154",
   "metadata": {},
   "source": [
    "Build two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05766d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=X_train.shape[1:])\n",
    "inputs_sid = keras.layers.Input(shape=(1,), dtype=tf.int32)\n",
    "#\n",
    "z = num2grid(5,x_min=-10, x_max=10, sigma=3.0)(inputs)\n",
    "z = keras.layers.Dense(30, activation=\"relu\")(z)\n",
    "output = keras.layers.Dense(1)(z)\n",
    "# output_biased = SubjectBias(num_subject, bias_scale=10.0, mean_reg_rate=1.0, name=\"bias_est\")([output, inputs_sid])\n",
    "output_biased = SubjectLinearTransform1D(num_subject, bias_scale=10.0, weight_mean_reg_rate=5.0, bias_mean_reg_rate=1.0, name=\"bias_est\")([output, inputs_sid])\n",
    "# Setup models\n",
    "model = keras.Model(inputs=[inputs], outputs=[output]) # pure\n",
    "model_biased = keras.Model(inputs=[inputs, inputs_sid], outputs=[output_biased]) # biased, for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "model_biased.compile(loss=\"mean_absolute_error\", optimizer=optimizer)\n",
    "#\n",
    "# model.compile(loss=\"mean_absolute_error\", optimizer=optimizer) # No need to compile this if it's not going to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a6e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_biased.fit([X_train, sid_train], y_train, epochs=100,\n",
    "                    validation_data=([X_valid, sid_valid], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca149f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_noBiaseNum_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433c7a5",
   "metadata": {},
   "source": [
    "The pure prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ee2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func(model.predict, mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_noBaisNum_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error(model.predict, func_dict, name=\"grid-noBiasNum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b2413",
   "metadata": {},
   "source": [
    "### Biased Prediction (according to SID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_bias = model_biased.get_layer(\"bias_est\").get_scaled_biases_np()\n",
    "mean_scaled_bias = np.sum(scaled_bias, axis=0)\n",
    "#\n",
    "print(\"scaled_bias = \\n%s\" % str(scaled_bias))\n",
    "print(\"\\nmean_scaled_bias = \\n%s\" % str(mean_scaled_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a675f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    output_scales = model_biased.get_layer(\"bias_est\").get_weights_np()\n",
    "    mean_scales = np.mean(output_scales, axis=0)\n",
    "    #\n",
    "    print(\"output_scales = \\n%s\" % str(output_scales))\n",
    "    print(\"\\nmean_scales = \\n%s\" % str(mean_scales))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16460e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_biase_sid(X, sid=1):\n",
    "    return model_biased.predict([X, tf.fill( (X.shape[0],1), sid)])\n",
    "\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "#\n",
    "draw_func(model.predict, mark='r-', linewidth=2, label=\"Predictions\")\n",
    "for _idx in range(num_subject):\n",
    "    _sid = _idx + 1\n",
    "    draw_func(lambda X: predict_with_biase_sid(X, _sid), mark='k--', linewidth=1, label=(\"sid=%d\" % _sid))\n",
    "#\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_noBaisNum_perSubjectCurve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbe2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40092303",
   "metadata": {},
   "source": [
    "# Combine Multi-Quantile Redgression with Per-Subject Transform Estimation (grid --> multi-quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba230fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile_list = [0.5]\n",
    "# quantile_list = [0.9]\n",
    "# quantile_list = [0.1, 0.9] # Use hidden layer with 30 neurons\n",
    "# quantile_list = [0.05, 0.95]\n",
    "# quantile_list = [0.25, 0.75]\n",
    "# quantile_list = [0.1, 0.5, 0.9]\n",
    "# quantile_list = [0.1, 0.3, 0.7, 0.9]\n",
    "# quantile_list = [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9] # remove 0.5\n",
    "quantile_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # Should use wider hidden layer (with many neurons) + L1 regularization\n",
    "num_quantile = len(quantile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of subjects\n",
    "num_subject = multiout_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=X_train.shape[1:])\n",
    "inputs_sid = keras.layers.Input(shape=(1,), dtype=tf.int32)\n",
    "#\n",
    "# z = inputs\n",
    "z = num2grid(5,x_min=-10, x_max=10, sigma=3.0)(inputs) # Convert to grid\n",
    "z = keras.layers.Dense(30, activation=\"relu\")(z)\n",
    "output = keras.layers.Dense(num_quantile)(z)\n",
    "# output_biased = SubjectBias(num_subject, bias_scale=10.0, mean_reg_rate=1.0, name=\"bias_est\")([output, inputs_sid])\n",
    "output_biased = SubjectLinearTransform1D(num_subject, bias_scale=10.0, weight_mean_reg_rate=5.0, bias_mean_reg_rate=1.0, name=\"bias_est\")([output, inputs_sid])\n",
    "# Setup models\n",
    "model = keras.Model(inputs=[inputs], outputs=[output]) # pure\n",
    "model_biased = keras.Model(inputs=[inputs, inputs_sid], outputs=[output_biased]) # biased, for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9)\n",
    "optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "model_biased.compile(loss=pinballLoss_full_fn, optimizer=optimizer)\n",
    "# model.compile(loss=pinballLoss_full_fn, optimizer=optimizer) # No need to compile this if it's not going to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37c998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_biased.fit([X_train, sid_train], y_train, epochs=100,\n",
    "                    validation_data=([X_valid, sid_valid], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d04b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"grid_NoBiasQuantile_training_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f1c9b",
   "metadata": {},
   "source": [
    "### Draw the \"pure\" mean prediction curve averaged from all quantile predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_noBiaseQuantile_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_error((lambda X: np.average(model.predict(X), axis=-1) ), func_dict, name=\"grid-noBiaseQuantileR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213fbdb",
   "metadata": {},
   "source": [
    "### Draw all \"pure\" quantile prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff824ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, y_train, \"b.\")\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "for _idx, _tau in enumerate(quantile_list):\n",
    "    draw_func((lambda X: model.predict(X)[:,_idx] ), mark='k--', linewidth=1, label=\"$y_{%d}$\" % (_tau*100))\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_quantile_all_quantiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7ec73",
   "metadata": {},
   "source": [
    "### Estimated Biases and Scales (according to SID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a79c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_bias = model_biased.get_layer(\"bias_est\").get_scaled_biases_np()\n",
    "mean_scaled_bias = np.sum(scaled_bias, axis=0)\n",
    "#\n",
    "print(\"scaled_bias = \\n%s\" % str(scaled_bias))\n",
    "print(\"\\nmean_scaled_bias = \\n%s\" % str(mean_scaled_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    output_scales = model_biased.get_layer(\"bias_est\").get_weights_np()\n",
    "    mean_scales = np.mean(output_scales, axis=0)\n",
    "    #\n",
    "    print(\"output_scales = \\n%s\" % str(output_scales))\n",
    "    print(\"\\nmean_scales = \\n%s\" % str(mean_scales))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493d1c8",
   "metadata": {},
   "source": [
    "### Plotting of mean quantiles for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2bd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_biase_sid(X, sid=1):\n",
    "    return np.average( model_biased.predict([X, tf.fill( (X.shape[0],1), sid)]), axis=1)\n",
    "\n",
    "draw_points(X_train, y_train, sid_train)\n",
    "#\n",
    "draw_func((lambda X: np.average(model.predict(X), axis=-1) ), mark='r-', linewidth=2, label=\"Predictions\")\n",
    "for _idx in range(num_subject):\n",
    "    _sid = _idx + 1\n",
    "    draw_func(lambda X: predict_with_biase_sid(X, _sid), mark='k--', linewidth=1, label=(\"sid=%d\" % _sid))\n",
    "#\n",
    "draw_normal_func(func_dict)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "# plt.axis([-3, 3, 0, 10])\n",
    "save_fig(\"grid_noBaisNum_perSubjectCurve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b87d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac8ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ec4fc4",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d764d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = print_all_prediction_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bdf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6a55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838a588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94dffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
